{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date Reader Challange Polimi 2017\n",
      "Loading data from ./DumpData/DataReaderTrainTestDump\n",
      "Dataset train-test loaded\n"
     ]
    }
   ],
   "source": [
    "from DataReader import DataReaderChallangePolimi2017\n",
    "import implicit\n",
    "from CB_asy import CB_asymmetric_cosine\n",
    "from CF_IB_asy import CF_IB_asymmetric_cosine\n",
    "from CF_UB_asy import CF_UB_asymmetric_cosine\n",
    "from implicit.nearest_neighbours import (BM25Recommender, CosineRecommender,TFIDFRecommender,ItemItemRecommender,all_pairs_knn)\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import pickle\n",
    "\n",
    "evaluation = True\n",
    "rebuild = False\n",
    "dr = DataReaderChallangePolimi2017(evaluation=evaluation,rebuild=rebuild)\n",
    "\n",
    "urm = dr.getURM_csr()\n",
    "t_p = dr.target_playlists\n",
    "t_t = dr.target_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bm25_row(self, X, K1=1.2, B=0.75):\n",
    "    #Weighs each row of a sparse matrix by OkapiBM25 weighting\n",
    "    # calculate idf per term (user)\n",
    "    X = sp.coo_matrix(X)\n",
    "    N = float(X.shape[0])\n",
    "    idf = log(N / (1 + bincount(X.col)))\n",
    "\n",
    "    # calculate length_norm per document (artist)\n",
    "    row_sums = np.ravel(X.sum(axis=1))\n",
    "    average_length = row_sums.mean()\n",
    "    length_norm = (1.0 - B) + B * row_sums / average_length\n",
    "\n",
    "    # weight matrix rows by bm25\n",
    "    X.data = X.data * (K1 + 1.0) / (K1 * length_norm[X.row] + X.data) * idf[X.col]\n",
    "    return X.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0702706944444\n"
     ]
    }
   ],
   "source": [
    "#track-artist\n",
    "icm = dr.getICM_csr(albums=False,artists=True,tags=False)\n",
    "icm = normalize(icm,axis=0)\n",
    "model = BM25Recommender(K=55)\n",
    "model.fit(icm)\n",
    "s = model.similarity\n",
    "s.setdiag(0)\n",
    "r_ar = urm*s.T\n",
    "r_ar = normalize(r_ar, axis=0)\n",
    "if evaluation: print dr.evaluateMAP(r_ar,verbose=False)\n",
    "r_ar = dr.reduceRM(r_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0702706944444\n"
     ]
    }
   ],
   "source": [
    "#track-artist\n",
    "icm = dr.getICM_csr(albums=False,artists=True,tags=False)\n",
    "icm = normalize(icm,axis=0)\n",
    "icm = dr.bm25_row(icm)\n",
    "s = all_pairs_knn(icm,55)\n",
    "s.setdiag(0)\n",
    "r_ar = urm*s.T\n",
    "r_ar = normalize(r_ar, axis=0)\n",
    "if evaluation: print dr.evaluateMAP(r_ar,verbose=False)\n",
    "r_ar = dr.reduceRM(r_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "icm = dr.getICM_csr(albums=False,artists=True,tags=False).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keep only k-similar item..\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "70000\n",
      "75000\n",
      "80000\n",
      "85000\n",
      "90000\n",
      "95000\n",
      "Building sparse matrix..\n"
     ]
    }
   ],
   "source": [
    "k=55\n",
    "data, rows, cols = [], [], []\n",
    "icm_t = icm.copy().T\n",
    "print(\"Keep only k-similar item..\")\n",
    "for i_row in range(icm.shape[0]):\n",
    "    if i_row%5000==0:\n",
    "        print i_row\n",
    "    row = icm[i_row, :]*icm_t\n",
    "    idxs = np.array(row.indices)\n",
    "    values = np.array(row.data)\n",
    "    k_top = min(k, values.shape[0])\n",
    "    topk_idxs_values = np.argpartition(values, -(k_top))[-(k_top):]\n",
    "    n = topk_idxs_values.shape[0]\n",
    "    # create incrementally the similarity matrix\n",
    "    data.extend(values[topk_idxs_values])\n",
    "    cols.extend(idxs[topk_idxs_values])\n",
    "    rows.extend(np.full(n, i_row))\n",
    "print(\"Building sparse matrix..\")\n",
    "s = sp.csr_matrix((data, (rows, cols)), shape=(icm.shape[0], icm.shape[0]), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0430385555556\n"
     ]
    }
   ],
   "source": [
    "r_ar = urm*s.T\n",
    "if evaluation: print dr.evaluateMAP(r_ar,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0701556944444\n"
     ]
    }
   ],
   "source": [
    "s2 = all_pairs_knn(icm,55)\n",
    "s2.setdiag(0)\n",
    "r_ar2 = urm*s2.T\n",
    "r_ar2 = normalize(r_ar2, axis=0)\n",
    "if evaluation: print dr.evaluateMAP(r_ar2,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012454.0\n"
     ]
    }
   ],
   "source": [
    "print sum(s2.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_fast1(m,k=100,verbose=True):\n",
    "    data, rows, cols = [], [], []\n",
    "    sim = (m * m.T).tocsr()\n",
    "    for i_row in range(sim.shape[0]):\n",
    "        if i_row%25000==0:\n",
    "            print i_row\n",
    "        row = sim[i_row, :]\n",
    "        idxs = np.array(row.indices)\n",
    "        values = np.array(row.data)\n",
    "        k_top = min(k, values.shape[0])\n",
    "        #topk_idxs_values = np.argpartition(values, -(k_top))[-(k_top):]\n",
    "        topk_idxs_values = np.argsort(-values)[-(k_top):]\n",
    "        n = topk_idxs_values.shape[0]\n",
    "        # create incrementally the similarity matrix\n",
    "        data.extend(values[topk_idxs_values])\n",
    "        cols.extend(idxs[topk_idxs_values])\n",
    "        rows.extend(np.full(n, i_row))\n",
    "    sim = sp.csr_matrix((data, (rows, cols)), shape=(sim.shape[0], sim.shape[0]), dtype=np.float32)\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def knn_fast2(m,k=100,verbose=True):\n",
    "    data, rows, cols = [], [], []\n",
    "    m = m.tocsr()\n",
    "    m_t = m.copy().T.tocsc()\n",
    "    for i_row in range(m.shape[0]):\n",
    "        if i_row%25000==0:\n",
    "            print i_row\n",
    "        row = m[i_row, :]*m_t\n",
    "        idxs = np.array(row.indices)\n",
    "        values = np.array(row.data)\n",
    "        k_top = min(k, values.shape[0])\n",
    "        #topk_idxs_values = np.argpartition(values, -(k_top))[-(k_top):]\n",
    "        topk_idxs_values = np.argsort(-values)[-(k_top):]\n",
    "        n = topk_idxs_values.shape[0]\n",
    "        # create incrementally the similarity matrix\n",
    "        data.extend(values[topk_idxs_values])\n",
    "        cols.extend(idxs[topk_idxs_values])\n",
    "        rows.extend(np.full(n, i_row))\n",
    "    sim = sp.csr_matrix((data, (rows, cols)), shape=(m.shape[0], m.shape[0]), dtype=np.float32)\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def knn_slow1(m,k=100,verbose=True):\n",
    "    data, rows, cols = [], [], []\n",
    "    m = m.tocsr()\n",
    "    sim = (m * m.T).tocsr()\n",
    "    for i_row in range(m.shape[0]):\n",
    "        if i_row%25000==0 and verbose:\n",
    "            print i_row\n",
    "        row = sim[i_row, :].toarray().ravel()\n",
    "        topk_idxs_values = np.argpartition(row, -(k))[-(k):]\n",
    "        #topk_idxs_values = np.argsort(row)[-(k):]\n",
    "        n = topk_idxs_values.shape[0]\n",
    "        # create incrementally the similarity matrix\n",
    "        data.extend(row[topk_idxs_values])\n",
    "        cols.extend(topk_idxs_values)\n",
    "        rows.extend(np.full(n, i_row))\n",
    "    s = sp.coo_matrix((data, (rows, cols)), shape=(m.shape[0], m.shape[0]), dtype=np.float32)\n",
    "    s.eliminate_zeros()\n",
    "    return s.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def knn_slow2(m,k=100,verbose=True):\n",
    "    data, rows, cols = [], [], []\n",
    "    m = m.tocsr()\n",
    "    m_t = m.copy().T.tocsc()\n",
    "    for i_row in range(m.shape[0]):\n",
    "        if i_row%10000==0 and verbose:\n",
    "            print i_row\n",
    "        row = (m[i_row, :]*m_t).toarray().ravel()\n",
    "        topk_idxs_values = np.argpartition(row, -(k))[-(k):]\n",
    "        n = topk_idxs_values.shape[0]\n",
    "        # create incrementally the similarity matrix\n",
    "        data.extend(row[topk_idxs_values])\n",
    "        cols.extend(topk_idxs_values)\n",
    "        rows.extend(np.full(n, i_row))\n",
    "    s = sp.coo_matrix((data, (rows, cols)), shape=(m.shape[0], m.shape[0]), dtype=np.float32)\n",
    "    s.eliminate_zeros()\n",
    "    return s.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "25000\n",
      "50000\n",
      "75000\n",
      "0.07046025\n"
     ]
    }
   ],
   "source": [
    "s = knn_slow1(icm, k=55)\n",
    "s.setdiag(0)\n",
    "r_ar = urm*s.T\n",
    "r_ar = normalize(r_ar, axis=0)\n",
    "if evaluation: print dr.evaluateMAP(r_ar,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012454.0\n"
     ]
    }
   ],
   "source": [
    "print sum(s.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "0.07046025\n"
     ]
    }
   ],
   "source": [
    "s = knn_slow2(icm, k=55)\n",
    "s.setdiag(0)\n",
    "r_ar = urm*s.T\n",
    "r_ar = normalize(r_ar, axis=0)\n",
    "if evaluation: print dr.evaluateMAP(r_ar,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keep only k-similar item..\n",
      "0\n",
      "25000\n",
      "50000\n",
      "75000\n",
      "Building sparse matrix..\n",
      "0.0700929166667\n"
     ]
    }
   ],
   "source": [
    "s = knn_fast1(icm, k=55)\n",
    "s.setdiag(0)\n",
    "r_ar = urm*s.T\n",
    "r_ar = normalize(r_ar, axis=0)\n",
    "if evaluation: print dr.evaluateMAP(r_ar,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012454.0\n"
     ]
    }
   ],
   "source": [
    "print sum(s.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "25000\n",
      "50000\n",
      "75000\n",
      "0.0700929166667\n"
     ]
    }
   ],
   "source": [
    "s = knn_fast2(icm, k=55)\n",
    "s.setdiag(0)\n",
    "r_ar = urm*s.T\n",
    "r_ar = normalize(r_ar, axis=0)\n",
    "if evaluation: print dr.evaluateMAP(r_ar,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keep only k-similar item..\n",
      "0\n",
      "25000\n",
      "50000\n",
      "75000\n",
      "Building sparse matrix..\n"
     ]
    }
   ],
   "source": [
    "k=55\n",
    "data, rows, cols = [], [], []\n",
    "icm = sp.csr_matrix(icm,dtype=np.float)\n",
    "sim = (icm * icm.T).tocsr()\n",
    "print(\"Keep only k-similar item..\")\n",
    "for i_row in range(icm.shape[0]):\n",
    "    if i_row%25000==0:\n",
    "        print i_row\n",
    "    row = sim[i_row, :]\n",
    "    idxs = np.array(row.indices)\n",
    "    values = np.array(row.data)\n",
    "    k_top = min(k, values.shape[0])\n",
    "    topk_idxs_values = np.argpartition(values, -(k_top))[-(k_top):]\n",
    "    n = topk_idxs_values.shape[0]\n",
    "    # create incrementally the similarity matrix\n",
    "    data.extend(values[topk_idxs_values])\n",
    "    cols.extend(idxs[topk_idxs_values])\n",
    "    rows.extend(np.full(n, i_row))\n",
    "print(\"Building sparse matrix..\")\n",
    "s = sp.csr_matrix((data, (rows, cols)), shape=(icm.shape[0], icm.shape[0]), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0699937777778\n"
     ]
    }
   ],
   "source": [
    "s.setdiag(0)\n",
    "r_ar = urm*s.T\n",
    "r_ar = normalize(r_ar, axis=0)\n",
    "if evaluation: print dr.evaluateMAP(r_ar,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
